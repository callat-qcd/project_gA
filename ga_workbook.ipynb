{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure style=\"float:right\">\n",
    "<a href=\"http://c51.lbl.gov/~walkloud/callat/\">\n",
    "    <img\n",
    "    src=\"./data/callat_logo.png\"\n",
    "    width=\"150\"\n",
    "    alt=\"CalLat logo\"\n",
    "    /img>\n",
    "</a>\n",
    "</figure>\n",
    "\n",
    "# Jupyter notebook for CalLat gA project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 16\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import lsqfit\n",
    "import gvar as gv\n",
    "import callat_ga_lib as xlib\n",
    "import sys\n",
    "print(\"python version:\", sys.version)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"numpy  version:\", np.__version__)\n",
    "print(\"scipy  version:\", sp.__version__)\n",
    "print(\"mpl    version:\", mpl.__version__)\n",
    "print(\"lsqfit version:\", lsqfit.__version__)\n",
    "print(\"gvar   version:\", gv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define analysis parameters\n",
    "* `switches['ensembles']` | list of strings\n",
    "    * select the ensembles that are used to perform the extrapolation\n",
    "    * the three rows correspond to the 0.15, 0.12, and 0.09 fm ensembles that are available\n",
    "* `switches['ansatz']` | dictionary\n",
    "    * define the fit ansatz for the extrapolation\n",
    "    * `['type']` | string: chooses between a Taylor expansion or Baryon Xpt\n",
    "        * Taylor expansion only includes even powers of ε<sub>π</sub>\n",
    "    * `['truncation']` | integer: is an integer n corresponding to the order of ε<sub>π</sub><sup>n</sup>\n",
    "    * `['FV']` | boolean: True turns on NLO FV corrections for both Baryon Xpt and Taylor\n",
    "    * `['xsb']` | boolean: True turns on am<sub>π</sub> term for Baryon Xpt\n",
    "    * `['alpha']` | boolean: True turns on α<sub>s</sub>a<sup>2</sup> for Baryon Xpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switches = dict()\n",
    "# Ensembles used in extrapolation\n",
    "switches['ensembles'] = [\n",
    "    'a15m400','a12m400','a09m400',\n",
    "    'a15m350','a12m350','a09m350',\n",
    "    'a15m310','a12m310','a09m310',\n",
    "    'a15m220','a12m220','a09m220','a12m220S','a12m220L',\n",
    "    'a15m130','a12m130'\n",
    "    ]\n",
    "switches['x_shift'] = {\n",
    "    'a15m400':0,    'a12m400':0,  'a09m400':0,\n",
    "    'a15m350':0,    'a12m350':0,  'a09m350':0,\n",
    "    'a15m310':0,    'a12m310':0,  'a09m310':0,\n",
    "    'a15m220':-.002,'a12m220':.00,'a09m220':.004,'a12m220S':-.003,'a12m220L':.002,\n",
    "    'a15m130':-.003,'a12m130':.001\n",
    "    }\n",
    "\n",
    "switches['ansatz'] = dict()\n",
    "### Type of fit: 'xpt_N', 'taylor_N', 'linear_N', 'constant_N', 'xpt-full_4', 'xpt-doublelog_4', 'xpt-delta_N'\n",
    "switches['ansatz']['type'] = ['xpt_3','xpt_4','taylor_2','taylor_4','linear_2','linear_4']\n",
    "#switches['ansatz']['type'] = ['xpt-delta_3']\n",
    "switches['ansatz']['FV'] = True # True turns on NLO FV correction\n",
    "switches['ansatz']['FVn'] = 3 # FV(epi^n) where n in [0,2,3]\n",
    "switches['ansatz']['xsb'] = False # True turns on O(a) discretization\n",
    "switches['ansatz']['alpha'] = False # True turns on O(alpha_s a^2) discretization\n",
    "\n",
    "### NOTEBOOK Report\n",
    "switches['report'] = dict()\n",
    "switches['report']['print_fit'] = False\n",
    "switches['report']['lecs'] = True #print LECs\n",
    "switches['report']['lecs_full'] = False #True print ALL LECs, False, print from lec list\n",
    "switches['report']['correlation'] = True\n",
    "\n",
    "### Save figs to local directory?\n",
    "switches['save_figs'] = True\n",
    "### plot tools \n",
    "switches['plot'] = dict()\n",
    "switches['plot']['raw_data'] = False\n",
    "switches['plot']['chiral'] = True\n",
    "switches['plot']['continuum'] = False\n",
    "switches['plot']['FV'] = False\n",
    "switches['plot']['model_avg_histogram'] = False\n",
    "### For the switches below to work\n",
    "### the corresponding plot above must be True\n",
    "switches['plot']['model_avg_chiral'] = True\n",
    "switches['plot']['model_avg_cont'] = False\n",
    "switches['plot']['model_avg_fv'] = False\n",
    "\n",
    "### multiplicative factor for prior width of epsilon_delta\n",
    "switches['eps_delta_sig'] = 0.05\n",
    "switches['axial_sig'] = 0.18 # 0.18 the optimal width based upon NLO fits and Bayes factors\n",
    "### inflation of prior widths\n",
    "### multiplicative factor for NxLO LECs\n",
    "p_lo = 1.\n",
    "p_nlo = 1.\n",
    "p_nnlo = 1.\n",
    "p_nnloa = 1.\n",
    "### prior width scaling for epi**3 FV function\n",
    "fv_3_width = 1.0\n",
    "### FV coefficient in Taylor expansion analyses\n",
    "g0_fv = 1.2\n",
    "g0_fv_width = 1. # loose-to-tight [1.0, 0.3, 0.1]\n",
    "### remove estimated QED corrections from mpi and Fpi\n",
    "switches['qed'] = False\n",
    "isospin = 0.00038 # Half the difference between analysis with and without QED corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define priors and PDG values\n",
    "`gvar` datatype has the form `gv.gvar(mean, standard deviation)`\n",
    "\n",
    "[gvar documentation](https://github.com/gplepage/gvar/blob/master/doc/gvar.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = dict()\n",
    "# Xpt priors\n",
    "priors['xpt'] = dict()\n",
    "priors['xpt']['g0'] = gv.gvar(1.0, p_lo*50.0) # LO LEC\n",
    "priors['xpt']['a1'] = gv.gvar(0.0, 1E-3) # DWF order a discretization\n",
    "priors['xpt']['c2'] = gv.gvar(0.0, p_nlo*50.0) # NLO counterterm epi^2\n",
    "priors['xpt']['c3'] = gv.gvar(0.0, p_nnlo*50.0) # NNLO LEC epi^3\n",
    "priors['xpt']['a2'] = gv.gvar(0.0, p_nlo*50.0) # NLO a^2\n",
    "priors['xpt']['s2'] = gv.gvar(0.0, 1.0) # NLO alpha_s a^2\n",
    "priors['xpt']['a4'] = gv.gvar(0.0, p_nnloa*p_nnlo*1.0) # NNNLO a^4\n",
    "priors['xpt']['b4'] = gv.gvar(0.0, p_nnlo*1.0) # NNNLO a^2 epi^2\n",
    "priors['xpt']['c4'] = gv.gvar(0.0, p_nnlo*1.0) # NNNLO epi^4\n",
    "priors['xpt']['gm4'] = gv.gvar(0.0, 50.0) # NNNLO log term\n",
    "priors['xpt']['gnd0'] = gv.gvar(-6./5*1.2,switches['axial_sig']*6/5*1.2) # delta LECs\n",
    "priors['xpt']['gdd0'] = gv.gvar(-9./5*1.2,switches['axial_sig']*9/5*1.2) # delta LECs\n",
    "priors['xpt']['f3'] = gv.gvar(0.,fv_3_width*23.0) # epi^3 FV coefficient # delta is 46.0 else 23.0\n",
    "# taylor priors\n",
    "priors['taylor'] = dict()\n",
    "priors['taylor']['g0'] = gv.gvar(g0_fv, p_nlo*g0_fv_width) # FV coefficient\n",
    "priors['taylor']['c0'] = gv.gvar(1.0, p_lo*50.0) # constant\n",
    "priors['taylor']['c2'] = gv.gvar(0.0, p_nlo*50.0) # epi^2\n",
    "priors['taylor']['a2'] = gv.gvar(0.0, p_nlo*50.0) # a^2\n",
    "priors['taylor']['c4'] = gv.gvar(0.0, p_nnlo*1.0) # epi^4\n",
    "priors['taylor']['a4'] = gv.gvar(0.0, p_nnloa*p_nnlo*1.0) # a^4\n",
    "priors['taylor']['b4'] = gv.gvar(0.0, p_nnlo*1.0) # a^2 epi^2\n",
    "priors['taylor']['f3'] = gv.gvar(0.,fv_3_width*18.0) # 18 epi^3 FV coefficient\n",
    "# linear priors\n",
    "priors['linear'] = dict()\n",
    "priors['linear']['g0'] = gv.gvar(g0_fv, p_nlo*g0_fv_width) # FV coefficient\n",
    "priors['linear']['c0'] = gv.gvar(1.0, p_lo*50.0) # constant\n",
    "priors['linear']['c2'] = gv.gvar(0.0, p_nlo*50.0) # epi\n",
    "priors['linear']['a2'] = gv.gvar(0.0, p_nlo*50.0) # a^2\n",
    "priors['linear']['a4'] = gv.gvar(0.0, p_nnloa*p_nnlo*1.0) # a^4\n",
    "priors['linear']['c4'] = gv.gvar(0.0, p_nnlo*1.0) # epi^2\n",
    "priors['linear']['f3'] = gv.gvar(0.,fv_3_width*12.5) # epi^3 FV coefficient\n",
    "# constant priors\n",
    "priors['constant'] = dict()\n",
    "priors['constant']['g0'] = gv.gvar(g0_fv, p_nlo*g0_fv_width) # FV coefficient\n",
    "priors['constant']['c0'] = gv.gvar(1.0, p_lo*10.0) # constant\n",
    "priors['constant']['a2'] = gv.gvar(0.0, p_nlo*10.0) # a^2\n",
    "priors['constant']['a4'] = gv.gvar(0.0, p_nnloa*p_nnlo*1.0) # a^4\n",
    "priors['constant']['f3'] = gv.gvar(0.,fv_3_width) # epi^3 FV coefficient\n",
    "\n",
    "\n",
    "# Physical parameters from PDG\n",
    "phys_params = dict()\n",
    "# http://pdg.lbl.gov/2016/tables/rpp2016-tab-mesons-light.pdf\n",
    "phys_params['mpi'] = gv.gvar(139.57018, 0.00035) # mpi +/- [MeV]\n",
    "# http://pdg.lbl.gov/2016/reviews/rpp2016-rev-pseudoscalar-meson-decay-cons.pdf\n",
    "phys_params['fpi'] = gv.gvar(130.2, 1.7) # fpi + ['MeV']\n",
    "# Turn off QED?\n",
    "if switches['qed']:\n",
    "    phys_params['mpi'] = gv.gvar(134.9770, 0.0005) # mpi 0 [MeV]\n",
    "    phys_params['fpi'] = gv.gvar(130.2, 1.7)/(1+0.5*gv.gvar(0.0169,.0015))\n",
    "# http://pdg.lbl.gov/2017/listings/rpp2017-list-Delta-1232.pdf\n",
    "phys_params['Delta'] = gv.gvar(293, 2) # Delta(1232) Breit Wigner Mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "[pandas dataframe documentation](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import correlator bootstraps\n",
    "gadf = pd.read_csv('./data/github_ga_v2.csv')\n",
    "gadf.groupby('ensemble').describe()[['ga','epi','mpil']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import HISQ parameters\n",
    "hqdf = pd.read_csv('./data/hisq_params.csv')\n",
    "hqdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xlib.format_data(switches, gadf, hqdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chiral-continuum fit\n",
    "[lsqfit documentation](https://github.com/gplepage/lsqfit/blob/master/doc/lsqfit.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = xlib.fit_data(switches, priors, data, phys_params)\n",
    "lecs = {\n",
    "    'xpt_2'      :['g0','c2'],\n",
    "    'xpt_3'      :['g0','c2','c3'],\n",
    "    'xpt_4'      :['g0','c2','c3','c4'],\n",
    "    'xpt-full_4' :['g0','c2','c3','c4','gm4'],\n",
    "    'xpt-delta_2':['g0','c2','gnd0','gdd0'],\n",
    "    'xpt-delta_3':['g0','c2','c3','gnd0','gdd0'],\n",
    "    'xpt-delta_4':['g0','c2','c3','c4','gnd0','gdd0'],\n",
    "    'taylor_2'   :['c0','c2','g0'],\n",
    "    'taylor_4'   :['c0','c2','c4','g0'],\n",
    "    'linear_2'   :['c0','c2','g0'],\n",
    "    'linear_4'   :['c0','c2','c4','g0'],\n",
    "}\n",
    "for a in switches['ansatz']['type']:\n",
    "    #print(result[a]['fit']) #uncomment to print entire fit results\n",
    "    print(\"\\n%s physical point result:\" %a, result[a]['phys']['result'])\n",
    "    print('%s, %s, %s, %s' %(result[a]['phys']['result'].mean, result[a]['phys']['result'].sdev, result[a]['fit'].chi2/result[a]['fit'].dof, result[a]['fit'].logGBF))\n",
    "    print(result[a]['fit'].dof)\n",
    "    if switches['report']['lecs']:\n",
    "        print('order-by-order contributions')\n",
    "        sub = result[a]['phys']['order'][0]\n",
    "        print('1: %s & %s' %(sub,100*sub/result[a]['phys']['result'].mean))\n",
    "        for idx,t in enumerate(result[a]['phys']['order'][1:]):\n",
    "            print('%s: %s & %s' %(2+idx,t-sub,100*(t-sub)/result[a]['phys']['result'].mean))\n",
    "            sub = t\n",
    "        print('LEC correlation matrix')\n",
    "        key_list = []\n",
    "        p_list = []\n",
    "        for k in result[a]['fit'].p.keys():\n",
    "            if switches['report']['lecs_full']:\n",
    "                if a in k:\n",
    "                    key_list.append(k)\n",
    "                    p_list.append(result[a]['fit'].p[k])\n",
    "            else:\n",
    "                if (a in k) and (k.split('_')[-1] in lecs[a]):\n",
    "                    key_list.append(k)\n",
    "                    p_list.append(result[a]['fit'].p[k])\n",
    "        # put LECS in human-sensible order\n",
    "        if not switches['report']['lecs_full']:\n",
    "            key_list2 = []\n",
    "            for k in lecs[a]:\n",
    "                for kn in key_list:\n",
    "                    if k in kn:\n",
    "                        key_list2.append(kn)\n",
    "        key_list = key_list2\n",
    "        pcorr = gv.evalcorr(p_list)\n",
    "        for idx1,k in enumerate(key_list):\n",
    "            string = ''\n",
    "            for idx2,l in enumerate(key_list):\n",
    "                string += '%.5f & ' %pcorr[idx1,idx2]\n",
    "            print(string,k,result[a]['fit'].p[k])\n",
    "    if switches['report']['print_fit']:\n",
    "        print(result[a]['fit'].format(maxline=True,pstyle='m'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systematic error budget\n",
    "The total uncertainty here differs from the paper because uncertainty from finite volume and isospin breaking have yet to be included. These two systematic uncertainties are estimated independently and added in quadrature after this analysis.\n",
    "\n",
    "In the paper, the input uncertainty is absorbed into the statistical uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = xlib.error_budget(switches,result)\n",
    "for a in switches['ansatz']['type']:\n",
    "    print(a)\n",
    "    print(pd.DataFrame.from_dict(error[a]['pct']).rename(index={0: 'pct. uncertainty'})[['stat','chiral','disc','fv','total']])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_list = dict()\n",
    "for a in switches['ansatz']['type']:\n",
    "    #print(a)\n",
    "    #print(error[a]['std'])\n",
    "    res_list[a] = result[a]['phys']['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results\n",
    "* chiral extrapolation\n",
    "* convergence of extrapolation\n",
    "* continuum extrapolation\n",
    "* infinite volume extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chiral extrapolation and series convergence\n",
    "if switches['plot']['chiral']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    r_chiral, r_converge = Plot.plot_chiral(switches,data,result)\n",
    "    mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuum extrapolation\n",
    "if switches['plot']['continuum']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    r_cont = Plot.plot_continuum(switches,data,result)\n",
    "    mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Infinite volume extrapolation at 220 MeV 0.12 fm\n",
    "if switches['plot']['FV']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    r_fv = Plot.plot_volume(switches,data,result)\n",
    "    mpl.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model averaging\n",
    "Model average with Bayes Factors provides more robust prediction than choosing any single result.\n",
    "\n",
    "From marginalizing over models $M_k$ for $k \\in \\{\\textrm{models}\\}$ we get the averaged posterior distribution to be:\n",
    "\n",
    "$P(g_A | \\textrm{data}) = \\sum_k P(g_A | M_k, \\textrm{data})P(M_k|\\textrm{data})$\n",
    "\n",
    "where\n",
    "\n",
    "$P(M_i|\\textrm{data}) = \\frac{\\textrm{BF}_i P(M_i)}{\\sum_k \\textrm{BF}_k P(M_k)} = \\frac{\\textrm{BF}_i}{\\sum_k \\textrm{BF}_k}$\n",
    "\n",
    "where the second equality is true if there are no a priori preferred models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extra uncertainties in quadrature\n",
    "error, plot_params = xlib.bma(switches,result,isospin)\n",
    "print('P(Mk|D) & result & model')\n",
    "for k in error['weights'].keys():\n",
    "    print('%.3f& %s & %s' %(error['weights'][k],str(result[k]['phys']['result']),k))\n",
    "#print('\\nmodel correlations')\n",
    "#mcorr = gv.evalcorr(error['gA_dict'])\n",
    "#for s in switches['ansatz']['type']:\n",
    "#    string = ''\n",
    "#    for t in switches['ansatz']['type']:\n",
    "#        string += '%.3f & ' %mcorr[(s,t)]\n",
    "#    print(string,s)\n",
    "print('\\ngA = %f +- %f +- %f' %(error['E(gA)'],error['s(gA)'],error['s(Mk)']))\n",
    "print ('percent uncertainty: %f +- %f' %(error['s(gA)']/error['E(gA)']*100,error['s(Mk)']/error['E(gA)']*100))\n",
    "print('\\ngA = %f, %f' %(error['E(gA)'],np.sqrt(error['s(gA)']**2+error['s(Mk)']**2)))\n",
    "\n",
    "print('percent uncertainty: %f' %(np.sqrt(error['s(gA)']**2+error['s(Mk)']**2)/error['E(gA)']*100))\n",
    "print(\"\\nError budget from extrapolation\")\n",
    "print(pd.DataFrame.from_dict(error['pct_budget']).rename(index={0: 'pct. err'})[['stat','chiral','disc','fv','isospin','model','total']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Between physical point and different pion masses\n",
    "\n",
    "- Use the resulting fits to compute the correlation between $g_A(m_\\pi^{phys})$ and $g_A(m_\\pi)$\n",
    "- Use this correlation to cmopute the shift in the physical point prediction due to a 1-$\\sigma$ fluctuation at the different pion mass points used in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switches['report']['correlation']:\n",
    "    xlib.mpi_corr(switches,phys_params,result,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if switches['plot']['model_avg_histogram']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    Plot.plot_histogram(switches,plot_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if switches['plot']['model_avg_chiral'] and switches['plot']['chiral']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    Plot.model_avg_chiral(switches,phys_params,error['weights'],r_chiral,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if switches['plot']['model_avg_cont'] and switches['plot']['continuum']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    Plot.model_avg_cont(switches,error['weights'],r_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if switches['plot']['model_avg_fv'] and switches['plot']['FV']:\n",
    "    Plot = xlib.plot_chiral_fit()\n",
    "    Plot.model_avg_fv(switches,error['weights'],r_fv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <span style=\"color: black; font-family: Helvetica; font-size: 2em\">\n",
    "        These calculations are made possible by\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "| | |\n",
    "|:---:|:---:|\n",
    "| [<img src='./data/incite_logo.png' width='200'/>](http://www.doeleadershipcomputing.org/)  | [<img src='./data/olcf_logo.png' width='320'/>](https://www.olcf.ornl.gov/) |\n",
    "| [<img src='./data/llnl_logo.png' width='640' />](https://hpc.llnl.gov/) | [<img src='./data/scidac_logo.png' width='350' />](http://www.scidac.gov/) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
